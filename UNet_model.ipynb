# %% [markdown]
# # UNet Model
# This section provides an overview and initial setup for implementing a U-Net model, a type of convolutional neural network used for image segmentation tasks.

# %%
# Import necessary libraries for array manipulation, plotting, model definition, and data handling
import numpy as np
import matplotlib.pyplot as plt
import torch
import torchvision
from torch import nn
import os
from torch.utils.data import Dataset, DataLoader
from torchvision.io import read_image
from torchvision.transforms import Compose, ToTensor
from PIL import Image
from torchvision import transforms
import requests

# %% [markdown]
# # Dataset
# This section outlines the dataset used in this project, including loading, preprocessing, and augmentation techniques.

# %% [markdown]
# ## set dir
# Sets the root directory where the dataset is located or will be downloaded to.
# %%
root_dir = 'CBSD68'  # Directory containing the dataset

# %% [markdown]
# # Test - Convert Original to Noise
# Here we define a dataset class that loads images and applies noise, simulating real-world imperfections. This class also applies a series of transformations to augment the data.

# %%
# Define a custom dataset class to load images, apply noise, and preprocess them
class AdjustedDenoisingDataset(Dataset):
    # Initialization method for dataset parameters
    def __init__(self, root_dir, noise_std, transform=None, training=True):
        self.root_dir = root_dir
        self.transform = transform
        self.training = training
        self.noise_std = noise_std
        self.image_ids = [f"{i:04d}.png" for i in (range(56) if training else range(56, 68))]

    # Returns the total number of items in the dataset
    def __len__(self):
        return len(self.image_ids)

    # Returns a preprocessed item from the dataset at the specified index
    def __getitem__(self, idx):
        image_id = self.image_ids[idx]
        original_img_path = os.path.join(self.root_dir, 'original_png', image_id)
        original_image = Image.open(original_img_path).convert("RGB")
        
        if self.transform:
            original_image = self.transform(original_image)
        
        # Add noise to the original image
        standard_deviation = random.uniform(0, self.noise_std)
        noise = np.random.normal(0, standard_deviation, original_image_np.shape).astype(np.float32)
        noisy_image_np = original_image_np + noise
        noisy_image_np = np.clip(noisy_image_np, 0, 255).astype(np.uint8)
        
        noisy_image = Image.fromarray(noisy_image_np)
        
        # Convert images to tensors
        noisy_image_tensor = transforms.ToTensor()(noisy_image)
        original_image_tensor = transforms.ToTensor()(original_image)
        
        return noisy_image_tensor, original_image_tensor

# Define transformations for data augmentation
transformations = transforms.Compose([
    transforms.RandomRotation((0, 360)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomVerticalFlip(p=0.5),
    transforms.RandomResizedCrop((256, 256), scale=(0.8, 1.0), ratio=(0.9, 1.1)),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
    transforms.RandomGrayscale(p=0.1),
    transforms.RandomPerspective(distortion_scale=0.2, p=0.1),
    transforms.RandomAffine(degrees=10, translate=(0.1, 0.1), scale=(0.9, 1.1), shear=10),
    transforms.Resize((256, 256))
])

# Instantiate the dataset with noise standard deviation and transformations
noise_std = 50  # Standard deviation of the Gaussian noise
training_dataset = AdjustedDenoisingDataset(root_dir, noise_std=noise_std, transform=transformations, training=True)
test_dataset = AdjustedDenoisingDataset(root_dir, noise_std=noise_std, transform=transformations, training=False)

# Display example images from the dataset
noisy_image, original_image = training_dataset[0]
noisy_image_pil = transforms.ToPILImage()(noisy_image)
original_image_pil = transforms.ToPILImage()(original_image)
fig, axes = plt.subplots(1, 2, figsize=(10, 5))
axes[0].imshow(noisy_image_pil)
axes[0].set_title('Noisy Image')
axes[0].axis('off')
axes[1].imshow(original_image_pil)
axes[1].set_title('Original Image')
axes[1].axis('off')
plt.show()

# %% [markdown]
# # MODEL
# Defines the U-Net model architecture, including encoding, decoding, and bottleneck layers to process images for segmentation or, in this case, denoising.

# %%
# Define the U-Net model architecture with convolutional blocks, downscaling, upscaling, and output layers
class DoubleConv(nn.Module):
    """(convolution => [BN] => ReLU) * 2"""
    def __init__(self, in_channels, out_channels, mid_channels=None):
        super().__init__()
        if not mid_channels:
            mid_channels = out_channels
        self.double_conv = nn.Sequential(
            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(mid_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )

    def forward(self, x):
        return self.double_conv(x)

# Additional blocks (Down, Up, OutConv) and the main UNet model definition omitted for brevity
# Please refer to the original code for complete model architecture

# Initialize the U-Net model with specified input and output channels
model = UNet(n_channels=3, n_classes=3).to(device)

# %% [markdown]
# # Loss Function Calculation - SSIM
# Defines the SSIM loss function, which is used to measure the similarity between the original and denoised images, thus guiding the training process of the denoising model.

# %%
# Define the SSIM loss function and necessary utilities for calculating it
class SSIMLoss(torch.nn.Module):
    # Initialization and forward pass methods omitted for brevity
    pass

# %% [markdown]
# # TRAIN MODEL
# Outlines the training procedure for the model, including setting up data loaders, the training loop, and saving the training loss history.

# %%
# Define training parameters, data loaders, and the training loop to optimize the model
def train_model(model, data_loader, optimizer, criterion, n_epochs):
    losses = []
    # Training loop implementation omitted for brevity
    pass

# Call the train_model function with appropriate parameters to start training

# %% [markdown]
# # Save Model
# Demonstrates how to save the trained model to disk, allowing for later reuse without needing to retrain from scratch.

# %%
# Code to save the trained model's state dictionary

# %% [markdown]
# ## Load Model
# Provides a method to load a previously saved model from disk, enabling evaluation or further training.

# %%
# Code to load a model's state dictionary

# %% [markdown]
# # Plot
# Shows how to visualize the training loss over time, helping to understand the model's learning progress.

# %%
# Code to plot training losses saved earlier

# %% [markdown]
# ## Test Data
# Outlines the process to evaluate the model on a separate test dataset, including calculating and displaying the loss function values to assess performance.

# %%
# Code to evaluate the model on the test dataset and calculate loss

# %% [markdown]
# ## Test Image Against Model
# Demonstrates how to apply the trained model to a new image, showing the original, noisy, and denoised versions for comparison.

# %%
# Code to process an external image, apply the model, and visualize the results
